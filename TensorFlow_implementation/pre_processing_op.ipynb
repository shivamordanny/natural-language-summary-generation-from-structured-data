{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the data to replicate baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/shivam/Documents/wikipedia-biography-dataset/wikipedia-biography-dataset/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_paths = {\n",
    "    \"table_content\": os.path.join(data_path, \"train.box\"),\n",
    "    \"nb_sentences\" : os.path.join(data_path, \"train.nb\"),\n",
    "    \"train_sentences\": os.path.join(data_path, \"train.sent\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and split into pairs(field and content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from the train.box file ...\n",
      "<class 'map'>\n",
      "splitting the samples into field_names and content_words ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading from the train.box file ...\")\n",
    "with open(data_files_paths[\"table_content\"]) as t_file:\n",
    "    # read all the lines from the file:\n",
    "    table_contents = t_file.readlines()\n",
    "    table_contents = map(lambda x: x.strip().split('\\t'), table_contents)\n",
    "    print(type(table_contents))\n",
    "    print(\"splitting the samples into field_names and content_words ...\")\n",
    "# convert this list of string pairs into list of lists of tuples\n",
    "table_contents = map(lambda y: map(lambda x: tuple(x.split(\":\")), y), table_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('name_1', 'walter'), ('name_2', 'extra'), ('image', '<none>'), ('image_size', '<none>'), ('caption', '<none>'), ('birth_name', '<none>'), ('birth_date_1', '1954'), ('birth_place', '<none>'), ('death_date', '<none>'), ('death_place', '<none>'), ('death_cause', '<none>'), ('resting_place', '<none>'), ('resting_place_coordinates', '<none>'), ('residence', '<none>'), ('nationality_1', 'german'), ('ethnicity', '<none>'), ('citizenship', '<none>'), ('other_names', '<none>'), ('known_for', '<none>'), ('education', '<none>'), ('alma_mater', '<none>'), ('employer', '<none>'), ('occupation_1', 'aircraft'), ('occupation_2', 'designer'), ('occupation_3', 'and'), ('occupation_4', 'manufacturer'), ('home_town', '<none>'), ('title', '<none>'), ('salary', '<none>'), ('networth', '<none>'), ('height', '<none>'), ('weight', '<none>'), ('term', '<none>'), ('predecessor', '<none>'), ('successor', '<none>'), ('party', '<none>'), ('boards', '<none>'), ('religion', '<none>'), ('spouse', '<none>'), ('partner', '<none>'), ('children', '<none>'), ('parents', '<none>'), ('relations', '<none>'), ('signature', '<none>'), ('website', '<none>'), ('footnotes', '<none>'), ('article_title_1', 'walter'), ('article_title_2', 'extra')], [('name_1', 'aaron'), ('name_2', 'hohlbein'), ('image', '<none>'), ('fullname_1', 'aaron'), ('fullname_2', 'hohlbein'), ('birth_date_1', '16'), ('birth_date_2', 'august'), ('birth_date_3', '1985'), ('birth_place_1', 'middleton'), ('birth_place_2', ','), ('birth_place_3', 'wisconsin'), ('birth_place_4', ','), ('birth_place_5', 'united'), ('birth_place_6', 'states'), ('height_1', '6'), ('height_2', '0'), ('position_1', 'defender'), ('currentclub', '<none>'), ('clubnumber', '<none>'), ('youthyears_1', '2003'), ('youthyears_2', '--'), ('youthyears_3', '2006'), ('youthclubs_1', 'wisconsin'), ('youthclubs_2', 'badgers'), ('years_1', '2003'), ('years_2', '--'), ('years_3', '2006'), ('years_4', '2006'), ('years_5', '2007'), ('years_6', '--'), ('years_7', '2010'), ('years_8', '2010'), ('years_9', '2011'), ('clubs_1', 'wisconsin'), ('clubs_2', 'badgers'), ('clubs_3', 'princeton'), ('clubs_4', '56ers'), ('clubs_5', 'kansas'), ('clubs_6', 'city'), ('clubs_7', 'wizards'), ('clubs_8', 'â†’'), ('clubs_9', 'miami'), ('clubs_10', 'fc'), ('clubs_11', '-lrb-'), ('clubs_12', 'loan'), ('clubs_13', '-rrb-'), ('clubs_14', 'fort'), ('clubs_15', 'lauderdale'), ('clubs_16', 'strikers'), ('caps_1', '12'), ('caps_2', '43'), ('caps_3', '10'), ('caps_4', '14'), ('goals_1', '0'), ('goals_2', '2'), ('goals_3', '0'), ('goals_4', '0'), ('nationalyears', '<none>'), ('nationalteam', '<none>'), ('nationalcaps', '<none>'), ('nationalgoals', '<none>'), ('medaltemplates', '<none>'), ('pcupdate_1', 'june'), ('pcupdate_2', '4'), ('pcupdate_3', ','), ('pcupdate_4', '2011'), ('ntupdate', '<none>'), ('article_title_1', 'aaron'), ('article_title_2', 'hohlbein')], [('name_1', 'majda'), ('name_2', 'vrhovnik'), ('image_1', 'majda'), ('image_2', 'vrhovnik.jpg'), ('image_size', '<none>'), ('caption', '<none>'), ('birth_name', '<none>'), ('birth_date_1', '14'), ('birth_date_2', 'april'), ('birth_date_3', '1922'), ('birth_place_1', 'ljubljana'), ('birth_place_2', ','), ('birth_place_3', 'kingdom'), ('birth_place_4', 'of'), ('birth_place_5', 'yugoslavia'), ('death_date_1', '04'), ('death_date_2', 'may'), ('death_date_3', '1945'), ('death_place_1', 'klagenfurt'), ('death_place_2', ','), ('death_place_3', 'nazi'), ('death_place_4', 'germany'), ('death_cause_1', 'shot'), ('resting_place_1', 'klagenfurt'), ('resting_place_2', ','), ('resting_place_3', 'austria'), ('resting_place_coordinates', '<none>'), ('residence', '<none>'), ('nationality_1', 'slovene'), ('other_names_1', 'lojzka'), ('known_for_1', 'people'), ('known_for_2', \"'s\"), ('known_for_3', 'hero'), ('known_for_4', 'of'), ('known_for_5', 'yugoslavia'), ('education_1', 'medicine'), ('alma_mater_1', 'faculty'), ('alma_mater_2', 'of'), ('alma_mater_3', 'medicine'), ('alma_mater_4', ','), ('alma_mater_5', 'university'), ('alma_mater_6', 'of'), ('alma_mater_7', 'ljubljana'), ('employer', '<none>'), ('occupation_1', 'espionage'), ('home_town', '<none>'), ('title', '<none>'), ('salary', '<none>'), ('networth', '<none>'), ('height', '<none>'), ('weight', '<none>'), ('term', '<none>'), ('predecessor', '<none>'), ('successor', '<none>'), ('party_1', 'communist'), ('boards', '<none>'), ('religion', '<none>'), ('spouse', '<none>'), ('partner', '<none>'), ('children', '<none>'), ('parents', '<none>'), ('relations', '<none>'), ('signature', '<none>'), ('website', '<none>'), ('footnotes', '<none>'), ('article_title_1', 'majda'), ('article_title_2', 'vrhovnik')], [('name_1', 'linda'), ('name_2', 'hayden'), ('image', '<none>'), ('imagesize', '<none>'), ('caption', '<none>'), ('birthname_1', 'linda'), ('birthname_2', 'm.'), ('birthname_3', 'higginson'), ('birth_date_1', '19'), ('birth_date_2', 'january'), ('birth_date_3', '1953'), ('birth_place_1', 'stanmore'), ('birth_place_2', ','), ('birth_place_3', 'middlesex'), ('birth_place_4', ','), ('birth_place_5', 'england'), ('death_date', '<none>'), ('death_place', '<none>'), ('othername', '<none>'), ('occupation_1', 'actress'), ('years_active', '<none>'), ('spouse', '<none>'), ('domesticpartner', '<none>'), ('website', '<none>'), ('article_title_1', 'linda'), ('article_title_2', 'hayden')], [('name_1', 'craig'), ('name_2', 'starcevich'), ('image', '<none>'), ('birth_date_1', '16'), ('birth_date_2', 'may'), ('birth_date_3', '1967'), ('birth_place', '<none>'), ('death_date', '<none>'), ('death_place', '<none>'), ('originalteam_1', 'east'), ('originalteam_2', 'perth'), ('originalteam_3', '-lrb-'), ('originalteam_4', 'wafl'), ('originalteam_5', '-rrb-'), ('debutdate_1', 'round'), ('debutdate_2', '1'), ('debutdate_3', ','), ('debutdate_4', '1987'), ('debutteam_1', 'collingwood'), ('debutopponent_1', 'sydney'), ('debutopponent_2', 'swans'), ('debutstadium_1', 'victoria'), ('debutstadium_2', 'park'), ('years_1', '1987'), ('years_2', '--'), ('years_3', '1993'), ('years_4', '1994'), ('years_5', '--'), ('years_6', '1995'), ('years_7', \"''\"), ('years_8', '`'), ('years_9', 'total'), ('years_10', \"''\"), ('years_11', \"'\"), ('clubs_1', 'collingwood'), ('clubs_2', 'brisbane'), ('clubs_3', 'bears'), ('statsend_1', '1995'), ('careerhighlights', '<none>'), ('article_title_1', 'craig'), ('article_title_2', 'starcevich')]]\n"
     ]
    }
   ],
   "source": [
    "x = [list(data) for data in table_contents]\n",
    "limited_data = x[:5]\n",
    "#print(limited_data)\n",
    "#len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove _1, _2 characters trailing in field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_integer(array):\n",
    "    new_array = []\n",
    "    for item_tuple in array:\n",
    "        item_array =list(item_tuple)\n",
    "        if len(item_array[0].split(\"_\")) > 1:\n",
    "            if item_array[0].split(\"_\")[-1].isdigit():\n",
    "                item_array[0] =\"_\".join(item_array[0].split(\"_\")[:-1])\n",
    "        new_array.append(item_array) \n",
    "    return (new_array)\n",
    "    \n",
    "edited_items = list(map(remove_integer, x))\n",
    "# edited_items = [item for subitem in editem_items for item in subitem]\n",
    "# list(map(remove_integer, limited_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a dictionary earlier, but that is of no use as of now\n",
    "'''\n",
    "dict_data = []\n",
    "for x in edited_items:\n",
    "    new_item_dict ={}\n",
    "    for y in x:\n",
    "        if y[1].lower() != \"<none>\":\n",
    "            new_item_dict[y[0].lower()] = y[1].lower()\n",
    "    dict_data.append(new_item_dict)\n",
    "print(dict_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove fields having None in their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for x in edited_items:\n",
    "    new_item_li =[]\n",
    "    for y in x:\n",
    "        if y[1].lower() != \"<none>\":\n",
    "            new_item_li.append(y)\n",
    "    processed_data.append(new_item_li)\n",
    "#print(processed_data)\n",
    "#print(new_item_li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate field names list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_list = []\n",
    "for li in processed_data:\n",
    "    for x in li:\n",
    "        field_list.append(x[0])\n",
    "#print(field_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6328"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(field_list)) #number of unique field names in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of occurence of each field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_field_names(lst):\n",
    "    elements = {}\n",
    "    for elem in lst:\n",
    "        if elem in elements.keys():\n",
    "            elements[elem] += 1\n",
    "        else:\n",
    "            elements[elem] = 1\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = count_field_names(field_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove field names occuring less than 100 times in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for key, value in count_dict.items():\n",
    "    if value > 100:\n",
    "        final_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "print(len(final_list)) #baseline vocubulary replicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'name',\n",
       " 'birth_date',\n",
       " 'nationality',\n",
       " 'occupation',\n",
       " 'occupation',\n",
       " 'occupation',\n",
       " 'occupation',\n",
       " 'article_title',\n",
       " 'article_title']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of list of tuples as baseline vocubulary replica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_li = []\n",
    "for x in processed_data:\n",
    "    one_iter = []\n",
    "    for y,z in zip(x, field_list):\n",
    "        if y[0] == z:\n",
    "            one_iter.append((z ,y[1]))\n",
    "    pre_processed_li.append(one_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582659"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_processed_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('name', 'walter'),\n",
       "  ('name', 'extra'),\n",
       "  ('birth_date', '1954'),\n",
       "  ('nationality', 'german'),\n",
       "  ('occupation', 'aircraft'),\n",
       "  ('occupation', 'designer'),\n",
       "  ('occupation', 'and'),\n",
       "  ('occupation', 'manufacturer'),\n",
       "  ('article_title', 'walter'),\n",
       "  ('article_title', 'extra')],\n",
       " [('name', 'aaron'),\n",
       "  ('name', 'hohlbein'),\n",
       "  ('clubs', '-lrb-'),\n",
       "  ('clubs', 'loan'),\n",
       "  ('clubs', '-rrb-'),\n",
       "  ('clubs', 'fort'),\n",
       "  ('clubs', 'lauderdale'),\n",
       "  ('clubs', 'strikers')],\n",
       " [('name', 'majda'), ('name', 'vrhovnik')],\n",
       " [('name', 'linda'), ('name', 'hayden')],\n",
       " [('name', 'craig'), ('name', 'starcevich'), ('birth_date', '16')]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_li[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
